# -*- coding: utf-8 -*-
"""MSQM_HA_ADA_Final_Project_2022v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D8O1y1_osvXLnRuMQI4k5klXNZHgGQYp

# Final Project
#### Advanced Data Analytics and Applications

Team 4


Last revision: 11/18/2022

**Update:**

- 11/14: Priminary models are built and embedding with Word2Vec.
- 11/15: tunning building training process
- 11/17: Building the models.
- 11/18: training on testing set

**Domain 2: Medical Text Domain**
Using a medical text library split into training and test, perform the following activities:

**Checklist:**

1. Verify the 5 categories as described in the dataset are applicable
2. Build a robust multi-category classifier to predict the 5 categories based on the training dataset (Naive-Bayes, Neural Networks, ML, Fasttext)

3. Evaluate performance on the test dataset

4. Do one of the following:
  1. Build a language model on the dataset using Fasttext or Word2Vec
  2. Use BM25 indexing to make the abstracts searchable
  3. Use topic modeling to identify themes beyond the 5 classes.
  4. Use spaCy to create an inventory of Named Entities for each abstract and  then use those to create a multi-label classifier
"""

!pip install --upgrade spacy
!python -m spacy download en_core_web_md

!pip install scikit-plot
!pip install keras
!pip install tensorflow
!pip install xgboost
!pip install scikit-plot

# Commented out IPython magic to ensure Python compatibility.
import spacy
import pandas as pd
import numpy as np
import sklearn
import string
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer 
from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()

import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import preprocess_string
from gensim.summarization.bm25 import BM25
from gensim.models.fasttext import FastText
import gensim.downloader as api

from pprint import pprint

from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold, GridSearchCV, cross_validate
from sklearn.metrics import log_loss, accuracy_score, classification_report, f1_score, roc_auc_score
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.svm import SVC
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.pipeline import make_pipeline,Pipeline


# %matplotlib inline
import seaborn as sns
import matplotlib.pyplot as plt
import scikitplot as skplt
import os

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

import keras

from keras.wrappers.scikit_learn import KerasClassifier
from keras.preprocessing.text import Tokenizer
from keras_preprocessing.sequence import pad_sequences
from keras.models import Sequential, Model 
from keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Flatten, Dropout, Input, Embedding, Concatenate
from keras.utils.np_utils import to_categorical
from keras.callbacks import ModelCheckpoint
from keras.models import load_model
from keras.optimizers import Adam
from keras import layers

nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
nltk.download('omw-1.4')

nlp = spacy.load('en_core_web_md')

"""#Task 1 Verify Labels
1.1 Verify the 5 categories as described in the dataset are applicable

Proposed Labels - unverified
1. neoplasm
2. digestive
3. nervous system
4. cardiovascular
5. general

## Download & Store data
"""

!wget https://duke.box.com/shared/static/zs05ep5f27monfdnhnl5l1q0qx1hn1us.zip -O medical_text.zip

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !unzip -d data/ medical_text.zip

#Seperation of labels and text data
labels = []
texts = []
with open("/content/data/train.dat", "r") as f:
     train_data = f.readlines() 

for line in train_data:
    splitline = line.split('\t')
    labels.append(splitline[0])
    texts.append(splitline[1])

f.close()
train_df = pd.DataFrame(   data = {'label': labels,
                                    'desc': texts   })

#Find desc with multiple-label
train_df['multi-label'] = 0
train_df.loc[train_df.duplicated('desc',keep=False),'multi-label'] = 1
train_df['multi-label'].value_counts()

#6140 rows with more than 1 label

duplicate = train_df[train_df['multi-label']==1]
duplicate = duplicate.groupby(duplicate.desc.tolist()).size().reset_index().rename(columns={0:'number'})
duplicate['number'].value_counts()

# 2653 row has 2 labels
# 270 rows has 3 labels
# 6 rows has 4 labels

# Identify unique desciption

train_df['unique'] = 0
train_df.loc[ (train_df.duplicated('desc')==False),'unique']= 1
train_df['unique'].sum()

!pip install Pillow
!pip install wordcloud

#Raise some examples: 
msg = duplicate.iloc[49]['index']

for i in train_df[train_df['desc']==msg].index:
  print('Index:', str(i))
  print('label:', train_df['label'][i])
  pprint(train_df['desc'][i][:300])
  print('\n')

#Prepare for mult-label classificaiton dataframe 

multi_df = train_df.copy()
multi_df['label'] = multi_df['label'].astype(int)-1

for i in range(0,5):
  multi_df[str(i)] = [1 if x == i else 0 for x in multi_df['label'] ]

multi_df = multi_df.groupby('desc').sum().reset_index().drop(['label','multi-label','unique'],axis=1)

multi_df.head(5)  #noted that the 5th row has both label 0 and 2

"""## Start with Multi-category Classification Process"""

#preprocess all label 1-5 > 0-4
train_df['label'] = train_df['label'].astype(int)-1

train_df['label'].value_counts().sort_index()
#_ imbalance dataset

dz_dict = {
  0 : 'Oncology',
  1 : 'Gastroenterology',
  2 : 'Neural disease',
  3 : 'Cardiovascular',
  4 : 'General'}

train_df['label_desc'] =train_df['label'].map(dz_dict)

#distribution
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5), dpi=80)
sns.countplot(x = train_df['label_desc'] ,palette='Set2')

def preprocess(text):
	stop_words = set(stopwords.words('english'))

	# Steps:
	# 1. lowercase
	# 2. Lammetize. (It does not stem. Try to preserve structure not to overwrap with potential acronym).
	# 3. Remove stop words.
	# 4. Remove punctuations.
	# 5. Remove character with the length size of 1.

	lowered = str.lower(text)
	word_tokens = word_tokenize(lowered)

	words = []
	for w in word_tokens:
		if w not in stop_words: 
			if w not in string.punctuation:
				if w not in ['``',"''",'--']:
					if len(w) > 1:
						lemmatized = lemmatizer.lemmatize(w)
						words.append(lemmatized)

	return words

#Step 1. manual review samples

for i in sorted(train_df['label'].unique()):
  print(f'Class: ' + train_df[train_df['label']==i].head(1)['label_desc'].values)
  pprint(str(i) + ' : ' + train_df[train_df['label']==i].iloc[:3]['desc'].values, width=200, compact = True)
  
# 1:  2/3 correct (1 general)
# 2:  3/3 correct
# 3:  3/3 correct
# 4:  3/3 correct
# 5:  1/3 correct (1 cardiovascular, 1 neoplasm)

# As we can see, the label of class 5 (general) is very unreliable

#Sanity check again for group 5 

for i in range(0,8):
  pprint(str(i)+ ' : ' + train_df[train_df['label']==4].iloc[i]['desc'][:500], width=100, compact=True)


# 1- Renal abscess in children - ID / General
# 2- Subclavian artery to innominate vein fistula - Cardiovascular [Wrong Label]
# 3- Mediastinal tracheostomy for esophageal cancer - Cancer [Wrong Label]
# 4- idiopathic fibroinflammatory - Derm / General
# 5- asthma  - Pulm / General
# 6- automatic implantable cardioverter defibrillator - cardiovascuar [Wrong label]
# 7- stress-related mucosal damage - GI [Wrong Label]
# 8- HSV  - ID / General 

# 4/8  ~ 50% with incorrect label

"""## Pre-Process"""

# https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794
# Classification

train_df['token'] = train_df['desc'].apply(lambda x: preprocess(x))
train_df['clean'] = [' '.join(x) for x in train_df['token']]
train_df.head()

multi_df['token'] = multi_df['desc'].apply(lambda x: preprocess(x))
multi_df['clean'] = [' '.join(x) for x in multi_df['token']]

multi_df.head()

from PIL import Image
import re
import requests
from wordcloud import WordCloud
#wordcloud visulization

x, y = np.ogrid[:300, :300]
mask = (x - 150) ** 2 + (y - 150) ** 2 > 130 ** 2
mask = 255 * mask.astype(int)

fig=plt.figure(figsize=(50,15))
columns = 5
for i in range(0, 5):
    fig.add_subplot(1, columns, i+1, title=f'{dz_dict[i]}')
    cloudwords = ' '.join(train_df[train_df['label']==i]['clean'])
    wordcloud = WordCloud(width = 800, height = 800, 
                background_color ='white', mask = mask,
                min_font_size = 10).generate(re.sub('patient','',cloudwords))
    plt.axis('off')
    plt.imshow(wordcloud)

plt.show()

# Just by looking at the world-cloud, Oncology and cardiology have many high frequency words specific to that group
# e.g., Tumor -> Cancer ;  Coronary artery -> Cardiovascular disease
# Ths word cloud also make us worry about the prediction accuracy in GI & General as they are very generic words

"""#Task 4: BM25 for search """

#utility Adapted from class 4
from IPython.display import display, Markdown, HTML

def get_top_n(bm25, query, n=5):
    
    # score docs
    scores = np.array(bm25.get_scores(query,1))
    
    # get indices of top N scores
    idx = np.argpartition(scores, -n)[-n:]
    
    # sort top N scores and return their indices
    return idx[np.argsort(-scores[idx])]

def mark(s, color='black'):
      return "<text style=color:{}>{}</text>".format(color, s)

def highlight(keywords, tokens, color='SteelBlue'):
    kw_set = set(keywords)
    tokens_hl = []
    
    for t in tokens:
        if t in kw_set:
            tokens_hl.append('<b>'+mark(t, color=color)+'</b>')
        else:
            tokens_hl.append(t)
    
    return " ".join(tokens_hl)

def color_label(labels):
  color = {
        0: 'Olive', #Cancer
        1: 'Gold', #GI
        2: 'SlateBlue', #Blu
        3: 'DeepPink', #CV
        4: 'SlateGray' #general
    }
  label_token = []
  for i in labels:    
    label_token.append(mark(dz_dict[i], color[i]))  
  return display(HTML('<h3>Label:' + ', '.join(label_token)))

bm25 = BM25(multi_df['token'])

test_query = ["cardiac"]

top_idx = get_top_n(bm25, test_query, n= 7)

for n,i in enumerate(top_idx):
  labels = [x for x in multi_df.iloc[i][1:6]]
  label = [idx for (idx,x) in enumerate(labels) if x ==1]

  display(HTML('<h3>Rank: '+str(n+1)+' Index:'+str(i) + '</h3>' ))
  color_label(label)
  
  display(HTML(highlight(test_query,
                 multi_df.iloc[i].token
                )))
  display(HTML('<br/>'))

"""# Task 2 Build the Model
Build a robust multi-category classifier to predict the 5 categories based on the training dataset (Naive-Bayes, Neural Networks, ML, Fasttext)
"""

#Set up for model training  70/30 split
X = train_df['token']
y = train_df['label']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, 
                                                    random_state = 42,
                                                    stratify = train_df.label.values #imbalance dataset
                                                    )

train_df['data_type'] = 0
train_df.loc[x_train.index,'data_type'] = 'train'
train_df.loc[x_test.index,'data_type'] = 'test'
train_df.head()

"""Check the vocabulary between training dataset and pre_trained model

https://www.kaggle.com/code/alhalimi/tokenization-and-word-embedding-compatibility

"""

def eval_model(X, y, model, probas = None):

    if probas == 1:            
      probas = cross_val_predict(model, X, y, cv=StratifiedKFold(n_splits = 5, shuffle = True, random_state = 42), 
                                  n_jobs=-1, method='predict_proba', verbose=2)
    else: 
      try:
        probas = model.predict_proba(X)
      except:
        probas = model.model.predict(X)

    eval_auc(y, probas)
    #print('ovr AUC: {}'.format(roc_auc_score(y, probas, multi_class = 'ovr')))
    #print('ovo AUC: {}'.format(roc_auc_score(y, probas, multi_class = 'ovo')))
    
    pred_indices = np.argmax(probas, axis=1)
    classes = np.unique(y)
    preds = classes[pred_indices]

    print('Accuracy: {}\n'.format(accuracy_score(y, preds)))
    skplt.metrics.plot_confusion_matrix(y, preds)
    print(classification_report(y, preds))


def eval_auc(y, probas):
  roc_auc_ovr = []
  classes = list(set(y))
  print('--------')
  for i in range(len(classes)):
    c = classes[i]

    y_auc = y.copy()
    y_auc = [1 if x == c else 0 for x in y_auc]
    y_probas = probas[:,i]
    roc_auc_ovr.append(roc_auc_score(y_auc, y_probas))
    print(f'class {i} AUC OvR: {roc_auc_ovr[i]:.3f}')

  print(f'Avg AUC OvR {np.mean(roc_auc_ovr):.3f}')
  print('--------')
  return roc_auc_ovr


def evaluate_features(X, y, model = LogisticRegression()):
  
    #scaler 
    scaler = MinMaxScaler()
    X = scaler.fit_transform(X)
   
    eval_model(X, y, model, probas = 1)

"""## TFIDF"""

#Tfidf

count_vectorizer = TfidfVectorizer(
    analyzer="word", tokenizer=nltk.word_tokenize,
    preprocessor=None, stop_words='english', max_features=None)    

tfidf = count_vectorizer.fit_transform(train_df['desc'])

len(count_vectorizer.get_feature_names())

tfidf_mean = np.mean(tfidf)

svd = TruncatedSVD(n_components=25, n_iter=25, random_state=12)
truncated_tfidf = svd.fit_transform(tfidf)

evaluate_features(truncated_tfidf, train_df['label'].values.ravel())

"""## Word2Vec"""

class MeanEmbeddingVectorizer(object):
    def __init__(self, word2vec):
        self.word2vec = word2vec 
        self.dim = len(word2vec.vectors[0])

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        #X = MyTokenizer().fit_transform(X)        
        return np.array([
            np.mean([self.word2vec[w] for w in words if w in self.word2vec.vocab]
                    or [np.zeros(self.dim)], axis=0)
            for words in X
        ])
    
    def fit_transform(self, X, y=None):
        return self.transform(X)

#Vectorize using pretrained model
#https://github.com/RaRe-Technologies/gensim-data

info = api.info()  # show info about available models/datasets
w2v_model = api.load("glove-wiki-gigaword-300")  # download the model and return as object ready for use

#Check Word2Vec dimension
w2v_model['word'].shape

"""### Vectorization"""

mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2v_model) #use pre-trained model from wiki
mean_embedded = mean_embedding_vectorizer.fit_transform(train_df['token'])

"""### Logistic regression"""

evaluate_features(mean_embedded, train_df['label'].values.ravel())

"""### Random Forest"""

evaluate_features(mean_embedded, train_df['label'].values.ravel(),
                  RandomForestClassifier(n_estimators=1000, max_depth=15, verbose=1))

"""### LightGBM"""

evaluate_features(mean_embedded, 
                  train_df['label'].values.ravel(),
                  LGBMClassifier(objective='multiclass', 
                                 learning_rate=0.01)
                 )

"""### Naive Bayes"""

evaluate_features(mean_embedded, 
                  train_df['label'].values.ravel(),
                  MultinomialNB()                  
                  )

"""###Neural Network"""

# define baseline model
def baseline_model():
	# create model
  model = Sequential()
  model.add(Dense(128, input_dim=300, activation='relu'))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(5, activation='softmax'))
  # Compile model
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

evaluate_features(mean_embedded, 
                  train_df['label'].values.ravel(),
                  KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=5, verbose=0)                
                  )

"""## FastText"""

!pip install fasttext
import fasttext

import os
# Prepare document 

def train_fasttext(data, x_col = 'clean', y_col = 'label' ,file = 'fast'):
  
  file_name = file + '_'   
  try:
    os.remove(file_name+'train')
    os.remove(file_name+'test')
    print('previous file deleted')
  except:
    print('no exist file')

  for x in ['train','test']:
    with open( file_name + x,'w') as f:
      for i in (data[data['data_type']==x]).index:
        f.write('__label__'+str(data[y_col][i])+' '+data[x_col][i])
        f.write('\n')
  f.close()   
  print('Complete loading file, Start training the model')   
  model =fasttext.train_supervised(input= file_name+'train', 
                                   epoch=25, 
                                   wordNgrams=2, 
                                   lr = 0.5)
  
  #evaluate the result 
  preds = []
  df = data[data['data_type']=='test']

  for i in df.index:
    preds.append(model.predict(df['clean'][i])[0][0][-1])

  print(classification_report(df['label'].astype(str), preds))
  skplt.metrics.plot_confusion_matrix(df['label'].astype(str), preds)

  return model

fasttext_model = train_fasttext(train_df)

#This should be classify as Cardivascular, but it is classify as General

fasttext_model.predict("Myocardial infarction is known as STEMI, require echocardiogram, this is wrong")

fasttext_model.predict("Myocardial infarction is known as STEMI, a.k.a. heart attack, require echocardiogram, this is wrong")

fasttext_model.predict("Lung cancer is one of the most lethal disease in the US")

fasttext_model.test("fast_test")

#Single label
#Precision 0.5
#Recall 0.5

fasttext_model.test("fast_test", k = 2)

#Multiple label
#Precision 0.4
#Recall 0.86

#Training set
preds = []
dataset = train_df[train_df['data_type']=='train']

for i in dataset.index:
  preds.append(fasttext_model.predict(train_df['clean'][i])[0][0][-1])

print(classification_report(dataset['label'].astype(str), preds))
skplt.metrics.plot_confusion_matrix(dataset['label'].astype(str), preds)

#Testing set
preds = []
dataset = train_df[train_df['data_type']=='test']

for i in dataset.index:
  preds.append(fasttext_model.predict(train_df['clean'][i])[0][0][-1])

print(classification_report(dataset['label'].astype(str), preds))
skplt.metrics.plot_confusion_matrix(dataset['label'].astype(str), preds)

"""So the result is suboptimal, how can we improve it ?

# [Method #1] Re-label class General

In above classification result, we can find that the models have difficulty to label class General. 

**Solution:**
1. Build the model without class General and evaluate the performance (LR, XGboost, FastText)
2. Attempt re-label class General

### Train model to classify 1-4
"""

# dataset 2 - without label 4 - general 
train_df_2 = train_df[train_df['label']!=4]
mean_embedded_2 = mean_embedding_vectorizer.fit_transform(train_df_2['token'])

#LR 
evaluate_features(mean_embedded_2, train_df_2['label'].values.ravel())

#ML LGB
evaluate_features(mean_embedded_2, 
                  train_df_2['label'].values.ravel(),
                  LGBMClassifier(objective='multiclass', 
                                 learning_rate=0.01)
                 )

def baseline_model():
	# create model
  model = Sequential()
  model.add(Dense(128, input_dim=300, activation='relu'))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(4, activation='softmax'))
  # Compile model
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

evaluate_features(mean_embedded_2, 
                  train_df_2['label'].values.ravel(),
                  KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=5, verbose=0)                
                  )

##Fast Text
fasttext_model_2 = train_fasttext(train_df_2)

#test this description from group 5
testing_msg =  train_df[train_df['label']==4]['clean'][6]
testing_msg

#This is indeed cancer 
fasttext_model_2.predict(testing_msg)

fasttext_model_2.test("fast_test")

#Single label
#Precision 0.78
#Recall 0.78

fasttext_model_2.test("fast_test",k = 2)

"""# [Method #2] Multi-label classification"""

multi_train, multi_test, y_train, y_test = train_test_split(  multi_df['token'], 
                                                              multi_df.drop(['desc','token','clean'],axis=1),
                                                              random_state=42, 
                                                              test_size=0.30, 
                                                              shuffle=True)

x_train = mean_embedding_vectorizer.fit_transform(multi_train)
x_test = mean_embedding_vectorizer.fit_transform(multi_test)

"""## Use Multiple One vs Rest Method"""

result = pd.DataFrame(columns=['accuracy','F1 score'])
result = result.append({'accuracy':'test'},ignore_index=True)
result

from sklearn.multiclass import OneVsRestClassifier
# Using pipeline for applying logistic regression and one vs rest classifier
LogReg_pipeline = Pipeline([
                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),
            ])

result = pd.DataFrame()
for category in range(0,5):

  category = str(category)
  # Training logistic regression model on train data
  LogReg_pipeline.fit(x_train, y_train[category])
  
  proba = LogReg_pipeline.predict_proba(x_test)
  prediction = LogReg_pipeline.predict(x_test)
  
  result = result.append({
      'AUC OvR' : round(roc_auc_score(y_test[category],proba[:,1]) ,3 ),
      'accuracy' : round(accuracy_score(y_test[category], prediction),3),
      'F1 score' : round(f1_score(y_test[category], prediction),3)
  },ignore_index= True)

result

"""## Classifier Chain"""

!pip install scikit-multilearn

#https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff

# using classifier chains
from skmultilearn.problem_transform import ClassifierChain

# initialize classifier chains multi-label classifier
classifier = ClassifierChain(LogisticRegression()).fit(x_train, y_train)
predictions = classifier.predict(x_test)

print("F1_score = ",f1_score(y_test,predictions,average='weighted'))
print("Accuracy = ",accuracy_score(y_test,predictions))
print("\n")

"""# Re-label Class 5 - General - Using fasttext"""

def fast_predict(label, desc):
  if label == 4:
    try:  #if threshold > 0.85, return new label, We intentially set it higher, so we don't over label people to other classes
      return fasttext_model_2.predict(desc, threshold= 0.85)[0][0][-1]
    except: #else return 4
      return label
  else:
    return label  

train_df['new_label'] = train_df[['label','clean']].apply(lambda x: fast_predict(x.label, x.clean), axis=1)
train_df['new_label'] = train_df['new_label'].astype(int)

train_df[train_df['label']==4].head(8)[['clean','label','new_label']]

#Let's go back to check if new classification is valid

# 1- Renal abscess in children - ID / General                                              - [Wrong] GI 
# 2- Subclavian artery to innominate vein fistula - Cardiovascular [Wrong Label]           - [Correct] Cardiovascular 
# 3- Mediastinal tracheostomy for esophageal cancer - Cancer [Wrong Label]                 - [Correct] Cancer 
# 4- idiopathic fibroinflammatory - Derm / General                                         - [wrong] cancer 
# 5- Asthma  - Pulm / General                                                              - [Correct] Geneneral 
# 6- automatic implantable cardioverter defibrillator - cardiovascuar [Wrong label]        - [Correct] cardiovascular 
# 7- stress-related mucosal damage - GI [Wrong Label]                                      - [Correct] GI 
# 8- HSV encephalitis - ID / General                                                       - [Correct] ID /General


# From observation, we find that FastText successfully learn the labels that we thought it was wrong, however, it also categorize some statement to other classes

train_df['new_label'].value_counts().sort_index()

#Evaluate with LR to check the classification report with new label system

evaluate_features(mean_embedded, train_df['new_label'].values.ravel())

evaluate_features(mean_embedded, 
                  train_df['new_label'].values.ravel(),
                  LGBMClassifier(objective='multiclass', 
                                 learning_rate=0.01)
                 )

"""#Task 2/3 Build models and evaluate performance"""

from google.colab import drive
import pickle
from gensim.test.utils import get_tmpfile

drive.mount('/content/drive')
file_path = 'drive/MyDrive/Duke/NLP/'

#embedding

mean_embedded_train = mean_embedding_vectorizer.fit_transform(train_df[train_df['data_type'] == 'train']['token'])
mean_embedded_test = mean_embedding_vectorizer.fit_transform(train_df[train_df['data_type'] == 'test']['token'])

y_train_new = train_df[train_df['data_type'] == 'train']['new_label']
y_test_new = train_df[train_df['data_type'] == 'test']['new_label']

"""### Naive Bayes

"""

pipe_nb = make_pipeline(MinMaxScaler(),
                        MultinomialNB()
)

naive = pipe_nb.fit(mean_embedded_train,y_train_new)

eval_model(X = MinMaxScaler().fit_transform(mean_embedded_test),
           y = y_test_new,
           model = naive   
)

pickle.dump(naive, open(file_path+'nb.model','wb'))  #NB

"""### LightGBM"""

param_grid = {
    'num_leaves': [31, 127],
    #'reg_alpha': [0.1, 0.5],
    'min_data_in_leaf': [30],
    }

lgb_estimator = LGBMClassifier(boosting_type='gbdt',  
                               objective='multiclass', 
                               learning_rate=0.01)

lgb_model = GridSearchCV(estimator=lgb_estimator, 
                        param_grid=param_grid, 
                        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)).fit(mean_embedded_train, y_train_new)

eval_model(mean_embedded_test,
           y_test_new,
           lgb_model.best_estimator_  
)

pickle.dump(lgb_model.best_estimator_, open(file_path+'lgbm.model','wb'))  #LGBM

"""### Neural Network"""

def baseline_model():
	# create model
  model = Sequential()
  model.add(Dense(128, input_dim=300, activation='relu'))
  model.add(Dense(64, activation='relu'))
  model.add(Dense(5, activation='softmax'))
  # Compile model
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model


NN_model = KerasClassifier(build_fn=baseline_model, 
                           epochs=30, 
                           batch_size=10, verbose=0).fit(mean_embedded_train, y_train_new, validation_split = 0.3 )


eval_model(X = mean_embedded_test,
           y = y_test_new,
           model = NN_model   
)

plt.title('Learning Curves')
plt.xlabel('Epoch')
plt.ylabel('Cross Entropy')
plt.plot(NN_model.history['loss'], label='train')
plt.plot(NN_model.history['val_loss'], label='val')
plt.legend()
plt.show()

#overfitting when Epoch > 3

NN_model = KerasClassifier(build_fn=baseline_model, 
                           epochs=3, 
                           batch_size=10, verbose=0).fit(mean_embedded_train, y_train_new)


eval_model(X = mean_embedded_test,
           y = y_test_new,
           model = NN_model   
)

NN_model.model.save(file_path+'NN.model') #NN

"""### FastText"""

final_fasttext = train_fasttext(train_df, 
                                x_col = 'clean',
                                y_col = 'new_label',
                                file = 'final_fast')

final_fasttext.save_model(file_path+'fasttext.model') #fast_test

"""# Label Test Data Set

"""

!head /content/data/test.dat

#Seperation of labels and text data

test_df = pd.DataFrame()

with open("/content/data/test.dat", "r") as f:
     test_data = f.readlines()
     f.close()

test_df = pd.DataFrame( data = { 'desc': test_data   })
test_df['token'] = [preprocess(x) for x in test_df.desc]

mean_embedding_test = mean_embedding_vectorizer.fit_transform(test_df['token'])

def sanity_check(model):
  try: 
    test_df['label'] = np.argmax(model.predict(mean_embedding_test), axis=1)
  except:
    test_df['label'] = model.predict(mean_embedding_test)
  
  test_df['label_desc'] =test_df['label'].map(dz_dict)
  preds = test_df['label_desc']
  plt.figure(figsize=(8, 5))
  sns.countplot(x = test_df['label_desc'].sort_values())  

  print('Distribution:')
  return preds

test_df['NN'] = sanity_check(NN_model.model)

test_df['lgbm'] = sanity_check(model= lgb_model.best_estimator_)

test_df['NB'] =sanity_check(model= naive)

test_df['FastText'] = [final_fasttext.predict(' '.join(x))[0][0][-1] for x in test_df['token']]
test_df['FastText'] = test_df['FastText'].astype(int).map(dz_dict)

plt.figure(figsize=[8,5])
sns.countplot(test_df['FastText'].sort_values())

test_df.head(10)

#let's doublec check what's going on with index 0, 2, 5, 9

for i in [0,2,5,9]:
  print('index:',i)
  pprint(test_df.iloc[i]['desc'],width=100)
  print('\n')

#0 -- it's a dermatology case, should be general 
#2 -- It's a pulmonary case with endobronchial polyp  -- general 
#5 -- It's Neurology case (Neural network is correct, others are wrong)
#9 -- It's a retinal artery obstscrtion from lymphoma -- both Oncology and Cardiovascular are correct